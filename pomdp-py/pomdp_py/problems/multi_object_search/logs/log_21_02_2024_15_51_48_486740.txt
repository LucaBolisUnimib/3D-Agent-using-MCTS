#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(0, 0, 0)|()): 1.0}
==== Step 1 ====
Action: look
Observation: MosOOObservation({0: (6, 7), 1: (1, 0), 2: None})
Reward: -1
Reward (Cumulative): -1
Find Actions Count: 0
__num_sims__: 403
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(0, 0, 0)|()): 1.0}
==== Step 2 ====
Action: look
Observation: MosOOObservation({0: None, 1: (1, 0), 2: None})
Reward: -1
Reward (Cumulative): -2
Find Actions Count: 0
__num_sims__: 340
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(0, 0, 0)|()): 1.0}
==== Step 3 ====
Action: find
Observation: MosOOObservation({})
Reward: 1000
Reward (Cumulative): 998
Find Actions Count: 1
__num_sims__: 535
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(0, 0, 0)|(1,)): 1.0}
==== Step 4 ====
Action: move-xyth-East
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 996
Find Actions Count: 1
__num_sims__: 584
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(1, 0, 0)|(1,)): 1.0}
==== Step 5 ====
Action: move-xyth-South
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 994
Find Actions Count: 1
__num_sims__: 526
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(1, 1, 1.5707963267948966)|(1,)): 1.0}
==== Step 6 ====
Action: move-xyth-East
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 992
Find Actions Count: 1
__num_sims__: 548
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(2, 1, 0)|(1,)): 1.0}
==== Step 7 ====
Action: move-xyth-South
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 990
Find Actions Count: 1
__num_sims__: 527
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(2, 2, 1.5707963267948966)|(1,)): 1.0}
==== Step 8 ====
Action: move-xyth-West
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 988
Find Actions Count: 1
__num_sims__: 514
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(1, 2, 3.141592653589793)|(1,)): 1.0}
==== Step 9 ====
Action: move-xyth-East
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 986
Find Actions Count: 1
__num_sims__: 377
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(2, 2, 0)|(1,)): 1.0}
==== Step 10 ====
Action: move-xyth-East
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 984
Find Actions Count: 1
__num_sims__: 411
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(3, 2, 0)|(1,)): 1.0}
==== Step 11 ====
Action: move-xyth-East
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 982
Find Actions Count: 1
__num_sims__: 476
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(4, 2, 0)|(1,)): 1.0}
==== Step 12 ====
Action: move-xyth-South
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 980
Find Actions Count: 1
__num_sims__: 469
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(4, 3, 1.5707963267948966)|(1,)): 1.0}
==== Step 13 ====
Action: move-xyth-North
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 978
Find Actions Count: 1
__num_sims__: 227
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(4, 2, 4.71238898038469)|(1,)): 1.0}
==== Step 14 ====
Action: move-xyth-South
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 976
Find Actions Count: 1
__num_sims__: 258
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(4, 3, 1.5707963267948966)|(1,)): 1.0}
==== Step 15 ====
Action: move-xyth-South
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 974
Find Actions Count: 1
__num_sims__: 390
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(4, 4, 1.5707963267948966)|(1,)): 1.0}
==== Step 16 ====
Action: move-xyth-East
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 972
Find Actions Count: 1
__num_sims__: 276
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(5, 4, 0)|(1,)): 1.0}
==== Step 17 ====
Action: look
Observation: MosOOObservation({0: None, 1: None, 2: (6, 4)})
Reward: -1
Reward (Cumulative): 971
Find Actions Count: 1
__num_sims__: 412
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(5, 4, 0)|(1,)): 1.0}
==== Step 18 ====
Action: find
Observation: MosOOObservation({})
Reward: 1000
Reward (Cumulative): 1971
Find Actions Count: 2
__num_sims__: 363
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(5, 4, 0)|(1, 2)): 1.0}
==== Step 19 ====
Action: move-xyth-South
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 1969
Find Actions Count: 2
__num_sims__: 253
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(5, 5, 1.5707963267948966)|(1, 2)): 1.0}
==== Step 20 ====
Action: move-xyth-East
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 1967
Find Actions Count: 2
__num_sims__: 401
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(6, 5, 0)|(1, 2)): 1.0}
==== Step 21 ====
Action: move-xyth-South
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 1965
Find Actions Count: 2
__num_sims__: 357
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2105263157894737, ObjectState(target,(6, 4)): 0.7368421052631579, ObjectState(target,(7, 6)): 0.052631578947368425}
Robot:  {RobotState(robot,(6, 6, 1.5707963267948966)|(1, 2)): 1.0}
==== Step 22 ====
Action: look
Observation: MosOOObservation({0: (6, 7), 1: None, 2: None})
Reward: -1
Reward (Cumulative): 1964
Find Actions Count: 2
__num_sims__: 357
#######################
Red object:  {ObjectState(target,(8, 3)): 0.22222222222222227, ObjectState(target,(6, 7)): 0.7777777777777778}
Green object:  {ObjectState(target,(1, 5)): 0.22222222222222227, ObjectState(target,(1, 0)): 0.7777777777777778}
Blue object:  {ObjectState(target,(5, 4)): 0.22222222222222227, ObjectState(target,(6, 4)): 0.7777777777777778}
Robot:  {RobotState(robot,(6, 6, 1.5707963267948966)|(1, 2)): 1.0}
==== Step 23 ====
Action: find
Observation: MosOOObservation({})
Reward: 1000
Reward (Cumulative): 2964
Find Actions Count: 3
__num_sims__: 363
Done!
