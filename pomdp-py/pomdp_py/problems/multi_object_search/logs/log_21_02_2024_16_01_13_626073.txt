#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(0, 0, 0)|()): 1.0}
==== Step 1 ====
Action: move-xyth-East
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): -2
Find Actions Count: 0
__num_sims__: 385
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(1, 0, 0)|()): 1.0}
==== Step 2 ====
Action: move-xyth-East
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): -4
Find Actions Count: 0
__num_sims__: 516
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(2, 0, 0)|()): 1.0}
==== Step 3 ====
Action: look
Observation: MosOOObservation({0: None, 1: (1, 0), 2: None})
Reward: -1
Reward (Cumulative): -5
Find Actions Count: 0
__num_sims__: 516
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(2, 0, 0)|()): 1.0}
==== Step 4 ====
Action: find
Observation: MosOOObservation({})
Reward: 1000
Reward (Cumulative): 995
Find Actions Count: 1
__num_sims__: 543
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(2, 0, 0)|(1,)): 1.0}
==== Step 5 ====
Action: move-xyth-West
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 993
Find Actions Count: 1
__num_sims__: 580
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(1, 0, 3.141592653589793)|(1,)): 1.0}
==== Step 6 ====
Action: move-xyth-East
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 991
Find Actions Count: 1
__num_sims__: 484
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(2, 0, 0)|(1,)): 1.0}
==== Step 7 ====
Action: move-xyth-West
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 989
Find Actions Count: 1
__num_sims__: 363
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(1, 0, 3.141592653589793)|(1,)): 1.0}
==== Step 8 ====
Action: move-xyth-South
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 987
Find Actions Count: 1
__num_sims__: 303
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(1, 1, 1.5707963267948966)|(1,)): 1.0}
==== Step 9 ====
Action: move-xyth-North
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 985
Find Actions Count: 1
__num_sims__: 370
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(1, 0, 4.71238898038469)|(1,)): 1.0}
==== Step 10 ====
Action: move-xyth-West
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 983
Find Actions Count: 1
__num_sims__: 312
#######################
Red object:  {ObjectState(target,(8, 3)): 0.2, ObjectState(target,(6, 7)): 0.7, ObjectState(target,(6, 0)): 0.05, ObjectState(target,(0, 8)): 0.05}
Green object:  {ObjectState(target,(1, 5)): 0.2, ObjectState(target,(1, 0)): 0.7, ObjectState(target,(6, 5)): 0.05, ObjectState(target,(3, 4)): 0.05}
Blue object:  {ObjectState(target,(5, 4)): 0.2, ObjectState(target,(6, 4)): 0.7, ObjectState(target,(8, 9)): 0.05, ObjectState(target,(7, 6)): 0.05}
Robot:  {RobotState(robot,(0, 0, 3.141592653589793)|(1,)): 1.0}
==== Step 11 ====
Action: move-xyth-East
Observation: MosOOObservation({})
Reward: -2
Reward (Cumulative): 981
Find Actions Count: 1
__num_sims__: 294
